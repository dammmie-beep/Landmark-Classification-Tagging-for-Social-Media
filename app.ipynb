{"cells":[{"cell_type":"markdown","metadata":{"id":"uaHfRtFFEWpP"},"source":["# Convolutional Neural Networks\n","\n","## Project: Write an Algorithm for Landmark Classification\n","\n","### A simple app\n","\n","In this notebook we build a very simple app that uses our exported model.\n","\n","> <img src=\"static_images/icons/noun-info-2558213.png\" alt=\"?\" style=\"width:25px\"/> Note how we are not importing anything from our source code (we do not use any module from the ``src`` directory). This is because the exported model, differently from the model weights, is a standalone serialization of our model and therefore it does not need anything else. You can ship that file to anybody, and as long as they can import ``torch``, they will be able to use your model. This is very important for releasing pytorch models to production.\n","\n","### Test your app\n","Go to a search engine for images (like Google Images) and search for images of some of the landmarks, like the Eiffel Tower, the Golden Gate Bridge, Machu Picchu and so on. Save a few examples locally, then upload them to your app to see how your model behaves!\n","\n","The app will show the top 5 classes that the model think are most relevant for the picture you have uploaded"],"id":"uaHfRtFFEWpP"},{"cell_type":"code","source":[],"metadata":{"id":"0XUmvt5xj9Qn"},"id":"0XUmvt5xj9Qn","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oNhn5aYvEWpg"},"outputs":[],"source":["from ipywidgets import VBox, Button, FileUpload, Output, Label\n","from PIL import Image\n","from IPython.display import display\n","import io\n","import numpy as np\n","import torchvision\n","import torchvision.transforms as T\n","import torch\n","\n","# Decide which model you want to use among the ones exported\n","learn_inf = torch.jit.load('checkpoints/original_exported.pt')\n","\n","def on_click_classify(change):\n","\n","    # Load image that has been uploaded\n","    fn = io.BytesIO(btn_upload.data[-1])\n","\n","    img = Image.open(fn)\n","    img.load()\n","\n","    # Let's clear the previous output (if any)\n","    out_pl.clear_output()\n","\n","    # Display the image\n","    with out_pl:\n","\n","        ratio = img.size[0] / img.size[1]\n","        c = img.copy()\n","        c.thumbnail([ratio * 200, 200])\n","        display(c)\n","\n","    # Transform to tensor\n","    timg = T.ToTensor()(img).unsqueeze_(0)\n","\n","    # Calling the model\n","    softmax = learn_inf(timg).data.cpu().numpy().squeeze()\n","\n","    # Get the indexes of the classes ordered by softmax\n","    # (larger first)\n","    idxs = np.argsort(softmax)[::-1]\n","\n","    # Loop over the classes with the largest softmax\n","    for i in range(5):\n","        # Get softmax value\n","        p = softmax[idxs[i]]\n","\n","        # Get class name\n","        landmark_name = learn_inf.class_names[idxs[i]]\n","\n","        labels[i].value = f\"{landmark_name} (prob: {p:.2f})\"\n","\n","\n","# Putting back btn_upload to a widget for next cell\n","btn_upload = FileUpload()\n","\n","btn_run = Button(description=\"Classify\")\n","btn_run.on_click(on_click_classify)\n","\n","labels = []\n","for _ in range(5):\n","    labels.append(Label())\n","\n","out_pl = Output()\n","out_pl.clear_output()\n","\n","wgs = [Label(\"Please upload a picture of a landmark\"), btn_upload, btn_run, out_pl]\n","wgs.extend(labels)\n","\n","VBox(wgs)"],"id":"oNhn5aYvEWpg"},{"cell_type":"markdown","metadata":{"id":"YppSuaDTEWpo"},"source":["## (optional) Standalone app or web app\n","\n","You can run this notebook as a standalone app on your computer by following these steps:\n","\n","1. Download this notebook in a directory on your machine\n","2. Download the model export (for example, ``checkpoints/transfer_exported.pt``) in a subdirectory called ``checkpoints`` within the directory where you save the app.ipynb notebook\n","3. Install voila if you don't have it already (``pip install voila``)\n","4. Run your app: ``voila app.ipynb --show_tracebacks=True``\n","5. Customize your notebook to make your app prettier and rerun voila\n","\n","You can also deploy this app as a website using Binder: https://voila.readthedocs.io/en/stable/deploy.html#deployment-on-binder"],"id":"YppSuaDTEWpo"},{"cell_type":"markdown","metadata":{"id":"pzPw8fd0EWpr"},"source":["# Create your submission archive\n","\n","Now that you are done with your project, please run the following cell. It will generate a file containing all the code you have written, as well as the notebooks. Please submit that file to complete your project"],"id":"pzPw8fd0EWpr"},{"cell_type":"code","source":["!python src/create_submit_pkg.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CA7i8auF7rT9","executionInfo":{"status":"ok","timestamp":1720705281868,"user_tz":-60,"elapsed":8198,"user":{"displayName":"Rashidat Sikiru","userId":"15700632060940602829"}},"outputId":"f58a4409-1322-41d0-d86f-ce49fa3efdcc"},"id":"CA7i8auF7rT9","execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["executing: jupyter nbconvert --to html transfer_learning.ipynb\n","[NbConvertApp] Converting notebook transfer_learning.ipynb to html\n","[NbConvertApp] Writing 1798334 bytes to transfer_learning.html\n","executing: jupyter nbconvert --to html cnn_from_scratch.ipynb\n","[NbConvertApp] Converting notebook cnn_from_scratch.ipynb to html\n","[NbConvertApp] Writing 1950541 bytes to cnn_from_scratch.html\n","executing: jupyter nbconvert --to html app.ipynb\n","[NbConvertApp] Converting notebook app.ipynb to html\n","[NbConvertApp] Writing 590947 bytes to app.html\n","Adding files to submission_2024-07-11T13h41m.tar.gz\n","src/__init__.py\n","src/helpers.py\n","src/optimization.py\n","src/predictor.py\n","src/train.py\n","src/data.py\n","src/model.py\n","src/transfer.py\n","src/create_submit_pkg.py\n","transfer_learning.ipynb\n","cnn_from_scratch.ipynb\n","app.ipynb\n","transfer_learning.html\n","cnn_from_scratch.html\n","app.html\n","\n","----------------------------------------------------------------\n","Done. Please submit the file submission_2024-07-11T13h41m.tar.gz\n","----------------------------------------------------------------\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"_T_A4U6M_EVS"},"id":"_T_A4U6M_EVS","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["References for all the Projects\n","\n","https://github.com/Kshishtawy/Landmark-Classification-and-Tagging-for-Social-Media-2.0/blob/main/app.html\n","\n","https://stackoverflow.com/questions/69979034/runtimeerror-pytorchstreamreader-failed-locating-file-data-pkl-file-not-found"],"metadata":{"id":"JYgQRzhh_VVR"},"id":"JYgQRzhh_VVR"},{"cell_type":"code","source":[],"metadata":{"id":"HBbViR-Z_ZKg"},"id":"HBbViR-Z_ZKg","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}